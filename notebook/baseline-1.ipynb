{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-24T17:42:50.017023Z","iopub.execute_input":"2023-03-24T17:42:50.017779Z","iopub.status.idle":"2023-03-24T17:42:50.056521Z","shell.execute_reply.started":"2023-03-24T17:42:50.017736Z","shell.execute_reply":"2023-03-24T17:42:50.055076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fucntions usefuls","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nimport pandas as pd \n\n\ndef effectif_int(data):\n    df = data.select_dtypes(include = ['int','float'])\n    df = df.describe().T\n    df.drop(columns='count', inplace=True)\n    return df \n\ndef type_of_vars(data):\n    typ_var = pd.DataFrame(data.dtypes)\n    typ_var.columns = ['Types variables']\n    return typ_var\n\n \n\n# class to plot missing values, convert types of variables \n\nclass Descriptive_analysis():\n  \"\"\" \n    Class to compute all types of descriptives analysis steps \n  \"\"\"\n  def __init__(self,\n              objective:str = 'survival') -> None:\n    self.objective = objective\n\n  def missing_values(self,\n                  X:pd.DataFrame):\n    \"\"\" Compute missing values df \"\"\"\n\n    self.X = X\n\n    #compute df of missing values sorted \n    self.miss = pd.DataFrame(X.isnull().sum())\n    self.miss.columns = ['Nans']\n    self.miss = self.miss.sort_values( by= ['Nans'], ascending= False)\n    self.miss = self.miss[self.miss.Nans != 0]\n    self.miss.reset_index(inplace=True)\n    self.miss = self.miss.rename(columns = {'index': 'Variables'})\n    if len(self.miss) == 0:\n        print('There is no missing values')\n    else :\n        return self.miss\n  \n\n  def plot_missing_values(self, X:pd.DataFrame,\n                              fig_size:list=[20,7],\n                              size_police: int= 10,\n                              threshold:float =None):\n    \"\"\"\" Plot missing values bar\"\"\"\n    self.X = X \n    self.fig_size = fig_size\n    self.size_police = size_police\n    self.threshold = threshold\n\n    if self.threshold == None:\n      self.threshold = np.round(X.shape[0]/2, 2)\n\n    #compute df for missing values\n    self.miss = self.missing_values(self.X)\n\n    #ploting features\n\n    plt.figure(figsize=(self.fig_size[0], self.fig_size[1]))\n    g = sns.barplot(x=\"Variables\", y=\"Nans\", data=self.miss[self.miss.Nans > self.threshold])\n    total = len(self.X)\n    for p in g.patches:\n      percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n      x = p.get_x() + p.get_width() / 2 - 0.05\n      y = p.get_y() + p.get_height()\n      g.annotate(percentage, (x, y), size = 10)\n    plt.title('Variables with more than ' + str(self.threshold)+ '% missing values' )\n    plt.show()\n\n\n  def define_dtypes(self, X:pd.DataFrame, \n                          category_columns:list=None,\n                          str_columns:list=None,\n                          date_columns:list=None,\n                          format_date:str=None,\n                          num_columns:str=None):\n    \"\"\" Convert variables \"\"\"\n    self.X = X\n    self.category_columns = category_columns\n    self.str_columns = str_columns\n    self.date_columns = date_columns\n    self.format_date = format_date\n    self.num_columns = num_columns\n\n    self.X[self.category_columns] = self.X[self.category_columns].astype('category')\n    self.X[self.str_columns] = self.X[self.str_columns].astype('str')\n    # date convertion\n    for date_c in self.date_columns:\n      self.X[date_c] = pd.to_datetime(self.X[date_c], format=self.format_date , errors='coerce')\n    if self.num_columns != None : \n      self.X[self.num_columns] = self.X[self.num_columns].astype('float')\n    else : \n      list_other_variables = list(set(self.X.columns)- set(self.category_columns))\n      list_other_variables = list(set(list_other_variables)- set(self.str_columns))\n      list_other_variables = list(set(list_other_variables)- set(self.date_columns))\n      self.X[list_other_variables] = self.X[list_other_variables].astype('float')\n    \n    return self.X\n\ndef concat_data(train_proteins, train_peptides, train_clinical):\n    # merge proteins and peptides \n    train_r = pd.merge(train_peptides, train_proteins, how='left', on=['visit_id','visit_month','patient_id','UniProt'])\n    # merge clinical \n    train_r = pd.merge(train_r, train_clinical, how='left', on=['visit_id','visit_month','patient_id'])\n    return train_r\n\n# metrics \ndef smape(y_true, y_pred):\n    smap = np.zeros(len(y_true))\n    \n    num = np.abs(y_true - y_pred)\n    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n    \n    pos_ind = (y_true!=0)|(y_pred!=0)\n    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n    \n    return 100 * np.mean(smap) \n\n\ndef mean_smape(y_true, y_pred):\n    res = 0\n    for i in range(y_true.shape[1]):\n        res = res + smape(y_true.iloc[:,i], y_pred.iloc[:,1])\n    return (res / 4) ","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:23:30.911728Z","iopub.execute_input":"2023-03-24T18:23:30.912114Z","iopub.status.idle":"2023-03-24T18:23:30.944177Z","shell.execute_reply.started":"2023-03-24T18:23:30.912079Z","shell.execute_reply":"2023-03-24T18:23:30.941990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction ","metadata":{}},{"cell_type":"markdown","source":"In this part :\n- we will see how we can apply non-parametric statistical test on data\n- create customs function sklearn for imputation (miceforest)\n- build baseline model (with and without protein/peptides)","metadata":{}},{"cell_type":"code","source":"# importing datasets\nimport numpy as np\nimport pandas as pd\nsample_submission = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/sample_submission.csv')\ntrain_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv')\ntest_proteins = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_proteins.csv')\ntrain_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\ntest_peptides = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test_peptides.csv')\ntrain_clinical = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\ntest = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/example_test_files/test.csv')\nsup = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T17:43:22.538711Z","iopub.execute_input":"2023-03-24T17:43:22.539181Z","iopub.status.idle":"2023-03-24T17:43:24.116219Z","shell.execute_reply.started":"2023-03-24T17:43:22.539138Z","shell.execute_reply":"2023-03-24T17:43:24.115056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = [train_proteins, train_peptides, train_clinical, sup]\ndata_name = ['train_proteins', 'train_peptides', 'train_clinical', 'sup']\nfor i in range(len(data)):\n    print('Shape of ',data_name[i] ,data[i].shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T17:49:04.931748Z","iopub.execute_input":"2023-03-24T17:49:04.932156Z","iopub.status.idle":"2023-03-24T17:49:04.939457Z","shell.execute_reply.started":"2023-03-24T17:49:04.932121Z","shell.execute_reply":"2023-03-24T17:49:04.938239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(data)):\n    print(data_name[i])\n    print('')\n    print(data[i].head())\n    print('---------------------------')\n    print('')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T17:51:20.976489Z","iopub.execute_input":"2023-03-24T17:51:20.976888Z","iopub.status.idle":"2023-03-24T17:51:21.002779Z","shell.execute_reply.started":"2023-03-24T17:51:20.976853Z","shell.execute_reply":"2023-03-24T17:51:21.001332Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concatenate datasets \ntrain = concat_data(train_proteins, train_peptides, train_clinical)\nprint(train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:17:36.990353Z","iopub.execute_input":"2023-03-24T18:17:36.990759Z","iopub.status.idle":"2023-03-24T18:17:37.627000Z","shell.execute_reply.started":"2023-03-24T18:17:36.990722Z","shell.execute_reply":"2023-03-24T18:17:37.625770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing values \ndescrip = Descriptive_analysis()\ndescrip.missing_values(train)  ","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:23:34.653589Z","iopub.execute_input":"2023-03-24T18:23:34.653984Z","iopub.status.idle":"2023-03-24T18:23:34.863349Z","shell.execute_reply.started":"2023-03-24T18:23:34.653947Z","shell.execute_reply":"2023-03-24T18:23:34.861932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"descrip.plot_missing_values(train, threshold=0, fig_size=[12,6])","metadata":{"execution":{"iopub.status.busy":"2023-03-24T18:24:00.661265Z","iopub.execute_input":"2023-03-24T18:24:00.661665Z","iopub.status.idle":"2023-03-24T18:24:01.132305Z","shell.execute_reply.started":"2023-03-24T18:24:00.661630Z","shell.execute_reply":"2023-03-24T18:24:01.130944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t","metadata":{},"execution_count":null,"outputs":[]}]}